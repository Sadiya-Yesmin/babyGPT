This is a minimal implementation of GPT (Generative Pretrained Transformer), inspired by Andrej Karpathy's YouTube tutorial. It builds a decoder-only Transformer from scratch using PyTorch.
Requirements

Python 3.7+

PyTorch

NumPy


